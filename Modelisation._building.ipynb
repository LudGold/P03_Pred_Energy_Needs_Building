{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les bibliotheques nécessaires\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "1. Import\n",
    "2. Préparation\n",
    "3. Baseline\n",
    "4. Modèles linéaires\n",
    "5. Modèles d’arbres\n",
    "6. Méthodes d’ensemble\n",
    "7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. CHARGEMENT ET PRÉPARATION DES DONNÉES\n",
      "Shape des données : (669, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>LargestPropertyUseTypeGFA</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>log_TotalGHGEmissions</th>\n",
       "      <th>log_SiteEnergyUse_kBtu</th>\n",
       "      <th>BuildingAge</th>\n",
       "      <th>AvgFloorArea</th>\n",
       "      <th>GFATotal_per_Building</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>88434</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1927</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>88434.0</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>47.61220</td>\n",
       "      <td>-122.33799</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.525373</td>\n",
       "      <td>15.793246</td>\n",
       "      <td>89</td>\n",
       "      <td>7369.500000</td>\n",
       "      <td>88434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>956110</td>\n",
       "      <td>759392</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>756493.0</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>47.61393</td>\n",
       "      <td>-122.33810</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.645053</td>\n",
       "      <td>18.100297</td>\n",
       "      <td>47</td>\n",
       "      <td>23319.756098</td>\n",
       "      <td>956110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61320</td>\n",
       "      <td>61320</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>61320.0</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>47.61412</td>\n",
       "      <td>-122.33664</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.660979</td>\n",
       "      <td>15.731637</td>\n",
       "      <td>90</td>\n",
       "      <td>6132.000000</td>\n",
       "      <td>61320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97288</td>\n",
       "      <td>60090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>Other</td>\n",
       "      <td>88830.0</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>47.61623</td>\n",
       "      <td>-122.33657</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.713106</td>\n",
       "      <td>16.307609</td>\n",
       "      <td>17</td>\n",
       "      <td>48644.000000</td>\n",
       "      <td>97288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83008</td>\n",
       "      <td>83008</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>81352.0</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>47.61390</td>\n",
       "      <td>-122.33283</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.176940</td>\n",
       "      <td>15.566239</td>\n",
       "      <td>90</td>\n",
       "      <td>7546.181818</td>\n",
       "      <td>83008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PropertyGFATotal  PropertyGFABuilding(s)  NumberofFloors  \\\n",
       "0             88434                   88434            12.0   \n",
       "1            956110                  759392            41.0   \n",
       "2             61320                   61320            10.0   \n",
       "3             97288                   60090             2.0   \n",
       "4             83008                   83008            11.0   \n",
       "\n",
       "   NumberofBuildings  YearBuilt PrimaryPropertyType  \\\n",
       "0                1.0       1927               Hotel   \n",
       "1                1.0       1969               Hotel   \n",
       "2                1.0       1926               Hotel   \n",
       "3                1.0       1999               Other   \n",
       "4                1.0       1926               Hotel   \n",
       "\n",
       "   LargestPropertyUseTypeGFA  ZipCode Neighborhood  Latitude  Longitude  \\\n",
       "0                    88434.0  98101.0     DOWNTOWN  47.61220 -122.33799   \n",
       "1                   756493.0  98101.0     DOWNTOWN  47.61393 -122.33810   \n",
       "2                    61320.0  98101.0     DOWNTOWN  47.61412 -122.33664   \n",
       "3                    88830.0  98101.0     DOWNTOWN  47.61623 -122.33657   \n",
       "4                    81352.0  98101.0     DOWNTOWN  47.61390 -122.33283   \n",
       "\n",
       "   ENERGYSTARScore  log_TotalGHGEmissions  log_SiteEnergyUse_kBtu  \\\n",
       "0             60.0               5.525373               15.793246   \n",
       "1             43.0               7.645053               18.100297   \n",
       "2             56.0               5.660979               15.731637   \n",
       "3             67.0               5.713106               16.307609   \n",
       "4             27.0               5.176940               15.566239   \n",
       "\n",
       "   BuildingAge  AvgFloorArea  GFATotal_per_Building  \n",
       "0           89   7369.500000                88434.0  \n",
       "1           47  23319.756098               956110.0  \n",
       "2           90   6132.000000                61320.0  \n",
       "3           17  48644.000000                97288.0  \n",
       "4           90   7546.181818                83008.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n1. CHARGEMENT ET PRÉPARATION DES DONNÉES\")\n",
    "df_work = pd.read_csv(\"clean_seattle.csv\")\n",
    "print(f\"Shape des données : {df_work.shape}\")\n",
    "df_work.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Variables numériques : 8\n",
      "✓ Variables catégorielles : 1\n",
      "✓ Variable cible : log_TotalGHGEmissions\n"
     ]
    }
   ],
   "source": [
    "num_cols = [\n",
    "    'PropertyGFATotal', 'AvgFloorArea',\n",
    "    'NumberofFloors', 'NumberofBuildings', \n",
    "    'BuildingAge', 'GFATotal_per_Building',\n",
    "    'Latitude', 'Longitude'\n",
    "]\n",
    "#  pour le moment on ne prend pas 'ENERGYSTARScore'\n",
    "cat_cols = ['PrimaryPropertyType']\n",
    "target = 'log_TotalGHGEmissions'\n",
    "print(f\"✓ Variables numériques : {len(num_cols)}\")\n",
    "print(f\"✓ Variables catégorielles : {len(cat_cols)}\")\n",
    "print(f\"✓ Variable cible : {target}\")\n",
    "\n",
    "# Préprocesseur - normaliser les données avant entrainement\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place de la validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration de la validation croisée\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste des métriques \n",
    "scoring = {\n",
    "    'MAE':  'neg_mean_absolute_error',\n",
    "    'RMSE': 'neg_root_mean_squared_error', \n",
    "    'R2':   'r2'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Split réalisé : 535 train, 134 test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sélection X, y - X étant les variables retenues et y la cible\n",
    "X = df_work[num_cols + cat_cols].copy()\n",
    "y = df_work[target]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"✓ Split réalisé : {len(X_train)} train, {len(X_test)} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MODÈLE BASELINE (DummyRegressor)\n",
      "--------------------------------------------------\n",
      "Baseline (DummyRegressor - moyenne) :\n",
      "  R2 CV    : -0.0362 ± 0.0418\n",
      "  RMSE CV  : 1.4525 ± 0.0256\n",
      "  MAE CV   : 1.1336 ± 0.0349\n",
      " on note ici que nos modèles à entrainer doivent avoir des résultats inférieurs au niveau des RMSE et MAE à ces moyennes de base\n",
      " pour le coéfficent de détermination (R^2) l'objectif est d'avoir une valeur supérieure à - 0.0362, l'idéal étant un score positif\n"
     ]
    }
   ],
   "source": [
    "# mise en place du modèle de base DummyRegressor - prédit juste la moyenne\n",
    "print(\"1. MODÈLE BASELINE (DummyRegressor)\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "dummy_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', DummyRegressor(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Cross-validation du baseline\n",
    "cv_dummy = cross_validate(dummy_pipe, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "baseline_r2 = cv_dummy['test_R2'].mean()\n",
    "baseline_rmse = -cv_dummy['test_RMSE'].mean()\n",
    "baseline_mae = -cv_dummy['test_MAE'].mean()\n",
    "\n",
    "print(f\"Baseline (DummyRegressor - moyenne) :\")\n",
    "print(f\"  R2 CV    : {baseline_r2:.4f} ± {cv_dummy['test_R2'].std():.4f}\")\n",
    "print(f\"  RMSE CV  : {baseline_rmse:.4f} ± {cv_dummy['test_RMSE'].std():.4f}\")\n",
    "print(f\"  MAE CV   : {baseline_mae:.4f} ± {cv_dummy['test_MAE'].std():.4f}\")\n",
    "print(f\" on note ici que nos modèles à entrainer doivent avoir des résultats inférieurs au niveau des RMSE et MAE à ces moyennes de base\") \n",
    "print(f\" pour le coéfficent de détermination (R^2) l'objectif est d'avoir une valeur supérieure à - 0.0362, l'idéal étant un score positif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. RÉGRESSION LINÉAIRE SIMPLE\n",
      "--------------------------------------------------\n",
      "Régression Linéaire (CV interne)\n",
      "  R^2 train CV : 0.5293 ± 0.0050\n",
      "  R^2  test  CV : 0.4518 ± 0.0145\n",
      "  RMSE train CV : 0.9899 ± 0.0045\n",
      "  RMSE test  CV : 1.0567 ± 0.0161\n",
      "  MAE train CV  : 0.7851 ± 0.0048\n",
      "  MAE test  CV  : 0.8321 ± 0.0203\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. RÉGRESSION LINÉAIRE SIMPLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# La régression linéaire sert de baseline pour comprendre\n",
    "# les relations linéaires dans nos données avant d'ajouter de la régularisation\n",
    "linear_pipe = Pipeline([('prep', preproc), ('model', LinearRegression())])\n",
    "cv_linear  = cross_validate(\n",
    "    linear_pipe,\n",
    "    X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True   # ← on récupère train_X et test_X\n",
    ")\n",
    "#ici on note une petite amélioration par rapport au baseline, on explique 23% de la variance ce qui est mieux et les métriques RMSE/MAE sont plus élévés en test qu'en entrainement mais\n",
    "#de manière modérée -voir ensuite avec des modèles de regularisation (ridge/lasso) et des méthodes non linéaires pour voir une amélioration de l'écart type\n",
    "print(\"Régression Linéaire (CV interne)\")\n",
    "print(f\"  R^2 train CV : {cv_linear ['train_R2'].mean():.4f} ± {cv_linear ['train_R2'].std():.4f}\")\n",
    "print(f\"  R^2  test  CV : {cv_linear ['test_R2'].mean():.4f} ± {cv_linear ['test_R2'].std():.4f}\")\n",
    "print(f\"  RMSE train CV : {-cv_linear ['train_RMSE'].mean():.4f} ± {cv_linear ['train_RMSE'].std():.4f}\")\n",
    "print(f\"  RMSE test  CV : {-cv_linear ['test_RMSE'].mean():.4f} ± {cv_linear ['test_RMSE'].std():.4f}\")\n",
    "print(f\"  MAE train CV  : {-cv_linear ['train_MAE'].mean():.4f} ± {cv_linear ['train_MAE'].std():.4f}\")\n",
    "print(f\"  MAE test  CV  : {-cv_linear ['test_MAE'].mean():.4f} ± {cv_linear ['test_MAE'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. MODÈLES RÉGULARISÉS (Ridge, Lasso, ElasticNet)\n",
      "--------------------------------------------------\n",
      "Optimisation des hyperparamètres par GridSearchCV...\n",
      "\n",
      "=== Résultats Régularisation ===\n",
      "\n",
      "Ridge :\n",
      "  Meilleurs paramètres : {'model': Ridge(), 'model__alpha': 0.01}\n",
      "  R^2 train CV : 0.5293\n",
      "  R^2 test  CV : 0.4519\n",
      "  RMSE train CV : 0.9899\n",
      "  RMSE test  CV : 1.0566\n",
      "  MAE train CV  : 0.7850\n",
      "  MAE test  CV  : 0.8319\n",
      "\n",
      "Lasso :\n",
      "  Meilleurs paramètres : {'model': Lasso(), 'model__alpha': 0.01}\n",
      "  R^2 train CV : 0.4787\n",
      "  R^2 test  CV : 0.3999\n",
      "  RMSE train CV : 1.0418\n",
      "  RMSE test  CV : 1.1056\n",
      "  MAE train CV  : 0.8267\n",
      "  MAE test  CV  : 0.8688\n",
      "\n",
      "ElasticNet :\n",
      "  Meilleurs paramètres : {'model': ElasticNet(), 'model__alpha': 0.01, 'model__l1_ratio': 0.1}\n",
      "  R^2 train CV : 0.4906\n",
      "  R^2 test  CV : 0.4152\n",
      "  RMSE train CV : 1.0298\n",
      "  RMSE test  CV : 1.0914\n",
      "  MAE train CV  : 0.8158\n",
      "  MAE test  CV  : 0.8557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"3. MODÈLES RÉGULARISÉS (Ridge, Lasso, ElasticNet)\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "#  La régularisation aide à :\n",
    "# - Ridge : réduire l'overfitting en pénalisant les coefficients élevés\n",
    "# - Lasso : sélection de variables en annulant certains coefficients\n",
    "# - ElasticNet : combinaison des avantages de Ridge et Lasso\n",
    "# modèles linéaires\n",
    "\n",
    "# Pipeline de base\n",
    "reg_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', Ridge())  # Placeholder qui sera remplacé par GridSearchCV\n",
    "])\n",
    "\n",
    "# Grille de paramètres - pour tester plusieurs combinaisons d'hyperparamètres pour donner le meilleur compromis biais/variance \n",
    "#alpha = force de pénalité pour essayer de réduire la variance (moins de sur-entrainement), stabiliser les poids de chaque feature, et sélectionner des variables via Lasso si nécessaire\n",
    "#Rideg pénalise la somme dess poids au carré, plus Alpha est grand plus les coeff sont retrécies vers 0, Lasso pénalise la somme des valeurs absolues et Elastic net combien les 2 (sélection et stabilisation)\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [Ridge()],\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0] # échelle logarithmique pour balayer plusieurs ordres de grandeur \n",
    "        #et voir si le modèle préfère une pénalité nulle, modérée ou forte\n",
    "    },\n",
    "    {\n",
    "        'model': [Lasso()],\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]  #idem\n",
    "    },\n",
    "    {\n",
    "        'model': [ElasticNet()],\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'model__l1_ratio': [0.1, 0.5, 0.7, 0.9] # curseur de mélange pour \"doser\" Lasso et Ridge - exemple 0.5 c'est 50% de Lasso et 50% de Ridge , 0.9 surtout Lasso et peu de Ridge\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Optimisation des hyperparamètres par GridSearchCV...\")\n",
    "gs_reg = GridSearchCV(\n",
    "    reg_pipe,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='RMSE', #moins standart que R^2 mais logique dans ma démarche\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # important pour avoir mean_train_...\n",
    ")\n",
    "gs_reg.fit(X_train, y_train) #on fit le jeu de données\n",
    "\n",
    "cv_res = gs_reg.cv_results_\n",
    "best_idx = gs_reg.best_index_   # l’indice de la meilleure config trouvée\n",
    "\n",
    "best_reg_r2   = cv_res['mean_test_R2'][best_idx]\n",
    "best_reg_rmse = -cv_res['mean_test_RMSE'][best_idx]\n",
    "best_reg_mae  = -cv_res['mean_test_MAE'][best_idx]\n",
    "\n",
    "# On récupère les meilleurs index par type\n",
    "best_ridge_idx = None\n",
    "best_lasso_idx = None\n",
    "best_enet_idx = None\n",
    "\n",
    "for i, p in enumerate(cv_res['params']):\n",
    "    if isinstance(p['model'], Ridge):\n",
    "        if best_ridge_idx is None or cv_res['mean_test_R2'][i] > cv_res['mean_test_R2'][best_ridge_idx]:\n",
    "            best_ridge_idx = i\n",
    "    elif isinstance(p['model'], Lasso):\n",
    "        if best_lasso_idx is None or cv_res['mean_test_R2'][i] > cv_res['mean_test_R2'][best_lasso_idx]:\n",
    "            best_lasso_idx = i\n",
    "    elif p['model'].__class__.__name__ == 'ElasticNet':\n",
    "        if best_enet_idx is None or cv_res['mean_test_R2'][i] > cv_res['mean_test_R2'][best_enet_idx]:\n",
    "            best_enet_idx = i\n",
    "\n",
    "print(\"\\n=== Résultats Régularisation ===\")\n",
    "\n",
    "for name, idx in [('Ridge', best_ridge_idx), ('Lasso', best_lasso_idx), ('ElasticNet', best_enet_idx)]:\n",
    "    if idx is None:\n",
    "        print(f\"{name} : Non testé\")\n",
    "        continue\n",
    "   \n",
    "    print(f\"\\n{name} :\")\n",
    "    print(f\"  Meilleurs paramètres : {cv_res['params'][idx]}\")\n",
    "    print(f\"  R^2 train CV : {cv_res['mean_train_R2'][idx]:.4f}\")\n",
    "    print(f\"  R^2 test  CV : {cv_res['mean_test_R2'][idx]:.4f}\")\n",
    "    print(f\"  RMSE train CV : {-cv_res['mean_train_RMSE'][idx]:.4f}\")\n",
    "    print(f\"  RMSE test  CV : {-cv_res['mean_test_RMSE'][idx]:.4f}\")\n",
    "    print(f\"  MAE train CV  : {-cv_res['mean_train_MAE'][idx]:.4f}\")\n",
    "    print(f\"  MAE test  CV  : {-cv_res['mean_test_MAE'][idx]:.4f}\")\n",
    "# ANALYSE :\n",
    "# Le modèle Ridge, avec une très faible pénalité (alpha=0.01), se révèle\n",
    "# être le meilleur des modèles régularisés, atteignant un R² test de 0.45.\n",
    "#\n",
    "# Fait intéressant, cette performance est quasi-identique à celle de la \n",
    "# régression linéaire simple. Cela indique que notre modèle linéaire \n",
    "# de base souffrait de très peu de sur-apprentissage, la régularisation \n",
    "# n'apporte donc pas de gain significatif à ce stade.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Première exploration des modèles non-linéaires (GradientBoosting et Random Forest)\n",
      "--------------------------------------------------\n",
      "→ Meilleurs params GradientBoost : {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "→ Meilleurs params RF : {'model__max_depth': 10, 'model__n_estimators': 300}\n",
      "\n",
      "=== Résultats Gradient Boosting ===\n",
      "R^2 train CV : 0.7669\n",
      "R^2 test  CV : 0.4855\n",
      "RMSE train CV : 0.6966\n",
      "RMSE test  CV : 1.0240\n",
      "MAE train CV : 0.5407\n",
      "MAE test  CV : 0.8183\n",
      "\n",
      "=== Résultats Random Forest ===\n",
      "R^2 train CV : 0.8630\n",
      "R^2 test  CV : 0.4464\n",
      "RMSE train CV : 0.5340\n",
      "RMSE test  CV : 1.0620\n",
      "MAE train CV : 0.4296\n",
      "MAE test  CV : 0.8521\n"
     ]
    }
   ],
   "source": [
    "print(\"4. Première exploration des modèles non-linéaires (GradientBoosting et Random Forest)\")\n",
    "print(\"-\"*50)\n",
    "# modèles d'arbres décisionnels - non linéaires - POUR VOIR SI ILS SURPASSENT LES MODELES LINEAIRES\n",
    "# --- Pipeline pour le Gradient Boosting ---\n",
    "boost_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# --- Grille d’hyper-paramètres (préfixe 'model__') ---\n",
    "param_grid_boost = {\n",
    "    'model__n_estimators':  [100, 200, 300], # nombre d'arbres déterminés, plus il y a d'arbres plus le modèle est capable de corriger les erreurs résiduelles mais plus long à entraîner\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2], # taux apprentissage - plus il est grand plus le modèle apprend vite mais risque de sur-apprentissage - 0.1 valeur par défaut - 0.01 plus lent mais plus stable et 0.2 plus rapide\n",
    "    'model__max_depth':     [3, 5, 7] # profondeur des arbres - 3 classique, 5 à 7 plus de flexibilité mais plus risqué\n",
    "}\n",
    "\n",
    "# --- Lancement de la GridSearch ---\n",
    "gs_boost = GridSearchCV(\n",
    "    boost_pipe,\n",
    "    param_grid_boost,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    refit='RMSE'\n",
    ")\n",
    "gs_boost.fit(X_train, y_train)\n",
    "print(\"→ Meilleurs params GradientBoost :\", gs_boost.best_params_)\n",
    "\n",
    "# Pipeline pour Random Forest\n",
    "rf_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Grille de recherche (attention au préfixe model__)\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth':    [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Lancement de la GridSearch\n",
    "gs_rf = GridSearchCV(\n",
    "    rf_pipe,\n",
    "    param_grid_rf,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    refit='RMSE',\n",
    "    return_train_score=True\n",
    ")\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(\"→ Meilleurs params RF :\", gs_rf.best_params_)\n",
    "\n",
    "# Récupère tous les scores CV pour Gradient Boosting\n",
    "cv_boost = gs_boost.cv_results_\n",
    "best_boost_idx = gs_boost.best_index_\n",
    "\n",
    "print(\"\\n=== Résultats Gradient Boosting ===\")\n",
    "print(f\"R^2 train CV : {cv_boost['mean_train_R2'][best_boost_idx]:.4f}\")\n",
    "print(f\"R^2 test  CV : {cv_boost['mean_test_R2'][best_boost_idx]:.4f}\")\n",
    "print(f\"RMSE train CV : {-cv_boost['mean_train_RMSE'][best_boost_idx]:.4f}\")\n",
    "print(f\"RMSE test  CV : {-cv_boost['mean_test_RMSE'][best_boost_idx]:.4f}\")\n",
    "print(f\"MAE train CV : {-cv_boost['mean_train_MAE'][best_boost_idx]:.4f}\")\n",
    "print(f\"MAE test  CV : {-cv_boost['mean_test_MAE'][best_boost_idx]:.4f}\")\n",
    "\n",
    "# Idem pour Random Forest\n",
    "cv_rf = gs_rf.cv_results_\n",
    "best_rf_idx = gs_rf.best_index_\n",
    "\n",
    "print(\"\\n=== Résultats Random Forest ===\")\n",
    "print(f\"R^2 train CV : {cv_rf['mean_train_R2'][best_rf_idx]:.4f}\")\n",
    "print(f\"R^2 test  CV : {cv_rf['mean_test_R2'][best_rf_idx]:.4f}\")\n",
    "print(f\"RMSE train CV : {-cv_rf['mean_train_RMSE'][best_rf_idx]:.4f}\")\n",
    "print(f\"RMSE test  CV : {-cv_rf['mean_test_RMSE'][best_rf_idx]:.4f}\")\n",
    "print(f\"MAE train CV : {-cv_rf['mean_train_MAE'][best_rf_idx]:.4f}\")\n",
    "print(f\"MAE test  CV : {-cv_rf['mean_test_MAE'][best_rf_idx]:.4f}\")\n",
    "\n",
    "# ANALYSE :\n",
    "# Les modèles non-linéaires montrent une nette amélioration par rapport\n",
    "# aux modèles linéaires.\n",
    "#\n",
    "# Le Gradient Boosting se distingue comme le meilleur modèle de cette\n",
    "# exploration, avec un R² test de 0.49, le score le plus élevé\n",
    "# obtenu jusqu'ici. L'écart train/test (0.77 -> 0.49) indique un\n",
    "# sur-apprentissage modéré mais maîtrisé.\n",
    "#\n",
    "# Le Random Forest, bien que très performant à l'entraînement (R² de 0.86),\n",
    "# généralise moins bien (R² test de 0.45) et souffre d'un sur-apprentissage\n",
    "# plus prononcé.\n",
    "#\n",
    "# Le Gradient Boosting est donc retenu comme le meilleur candidat\n",
    "# de cette catégorie grâce à sa performance supérieure et sa meilleure robustesse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthodes d'ensemble : Bagging / Boosting / Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. MÉTHODES D'ENSEMBLE\n",
      "--------------------------------------------------\n",
      "A) BAGGING (Bootstrap Aggregating)\n",
      "R^2 train : 0.7389\n",
      "R^2 test  : 0.4762\n",
      "RMSE train : 0.7378\n",
      "RMSE test  : 0.9935\n",
      "MAE train  : 0.5720\n",
      "MAE test   : 0.7938\n",
      "\n",
      "B) BOOSTING (Gradient Boosting)\n",
      "R^2 train : 0.5794\n",
      "R^2 test  : 0.4052\n",
      "RMSE train : 0.9364\n",
      "RMSE test  : 1.0586\n",
      "MAE train  : 0.7430\n",
      "MAE test   : 0.8348\n",
      "\n",
      "C) STACKING\n",
      "R^2 train : 0.7383\n",
      "R^2 test  : 0.2997\n",
      "RMSE train : 0.7387\n",
      "RMSE test  : 1.1487\n",
      "MAE train  : 0.5843\n",
      "MAE test   : 0.8633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n5. MÉTHODES D'ENSEMBLE\")\n",
    "print(\"-\" * 50)\n",
    "# Techniques pour combiner plusieurs modèles\n",
    "# A) BAGGING - Réduit la variance en combinant plusieurs modèles entraînés sur\n",
    "# différents échantillons des données d'entraînement\n",
    "print(\"A) BAGGING (Bootstrap Aggregating)\")\n",
    "bagging_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', BaggingRegressor(\n",
    "        n_estimators=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "cv_bagging = cross_validate(bagging_pipe, X_train, y_train,cv=cv, scoring=scoring)\n",
    "\n",
    "best_boost = gs_boost.best_estimator_\n",
    "best_boost.fit(X_train, y_train)\n",
    "y_pred_train_boost = best_boost.predict(X_train)\n",
    "y_pred_test_boost  = best_boost.predict(X_test)\n",
    "print(f\"R^2 train : {r2_score(y_train, y_pred_train_boost):.4f}\") # gain modeste par rapport aux linéaires (≃0.25), mais écart train/test ≃0.26  \n",
    "print(f\"R^2 test  : {r2_score(y_test,  y_pred_test_boost):.4f}\") # montre un sur‐apprentissage toujours présent.  \n",
    "print(f\"RMSE train : {np.sqrt(mean_squared_error(y_train, y_pred_train_boost)):.4f}\")\n",
    "print(f\"RMSE test  : {np.sqrt(mean_squared_error(y_test,  y_pred_test_boost)):.4f}\")\n",
    "print(f\"MAE train  : {mean_absolute_error(y_train, y_pred_train_boost):.4f}\")\n",
    "print(f\"MAE test   : {mean_absolute_error(y_test,  y_pred_test_boost):.4f}\")\n",
    "\n",
    "# B) BOOSTING\n",
    "print(\"\\nB) BOOSTING (Gradient Boosting)\")\n",
    "# Justification : Réduit le biais en combinant séquentiellement des modèles faibles,\n",
    "# chaque nouveau modèle corrigeant les erreurs du précédent\n",
    "\n",
    "boosting_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', HistGradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Optimisation des hyperparamètres pour le boosting\n",
    "param_grid_boost = {\n",
    "    'model__max_iter': [100, 200],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "gs_boost = GridSearchCV(boosting_pipe, param_grid_boost, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_boost.fit(X_train, y_train)\n",
    "\n",
    "cv_boost_results = cross_validate(gs_boost.best_estimator_, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "best_boost = gs_boost.best_estimator_\n",
    "best_boost.fit(X_train, y_train)\n",
    "y_pred_train_boost = best_boost.predict(X_train)\n",
    "y_pred_test_boost  = best_boost.predict(X_test)\n",
    "print(f\"R^2 train : {r2_score(y_train, y_pred_train_boost):.4f}\") #étonnant - même résultat que bagging \n",
    "print(f\"R^2 test  : {r2_score(y_test,  y_pred_test_boost):.4f}\")\n",
    "print(f\"RMSE train : {np.sqrt(mean_squared_error(y_train, y_pred_train_boost)):.4f}\")\n",
    "print(f\"RMSE test  : {np.sqrt(mean_squared_error(y_test,  y_pred_test_boost)):.4f}\")\n",
    "print(f\"MAE train  : {mean_absolute_error(y_train, y_pred_train_boost):.4f}\")\n",
    "print(f\"MAE test   : {mean_absolute_error(y_test,  y_pred_test_boost):.4f}\")\n",
    "\n",
    "# C) STACKING\n",
    "print(\"\\nC) STACKING\")\n",
    "# Justification : Combine les prédictions de plusieurs modèles via un meta-learner\n",
    "# qui apprend comment optimiser la combinaison\n",
    "\n",
    "# Modèles de base pour le stacking\n",
    "base_models = [\n",
    "    ('ridge', gs_reg.best_estimator_['model']),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    ('gb', gs_boost.best_estimator_['model'])\n",
    "]\n",
    "\n",
    "stacking_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LinearRegression(),\n",
    "        cv=3,  # CV interne pour éviter l'overfitting\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv_stacking = cross_validate(stacking_pipe, X_train, y_train, cv=cv, scoring=scoring)\n",
    "stacking_pipe.fit(X_train, y_train)\n",
    "y_pred_train_stacking = stacking_pipe.predict(X_train)\n",
    "y_pred_test_stacking  = stacking_pipe.predict(X_test)\n",
    "print(f\"R^2 train : {r2_score(y_train, y_pred_train_stacking):.4f}\") # +0.08 de R2 test par rapport à Bagging/Boosting\n",
    "print(f\"R^2 test  : {r2_score(y_test,  y_pred_test_stacking):.4f}\")  #avec un écart train/test réduit (0.33 vs 0.26)   \n",
    "print(f\"RMSE train : {np.sqrt(mean_squared_error(y_train, y_pred_train_stacking)):.4f}\")# meilleure maîtrise du sur‐apprentissage.\n",
    "print(f\"RMSE test  : {np.sqrt(mean_squared_error(y_test,  y_pred_test_stacking)):.4f}\")\n",
    "print(f\"MAE train  : {mean_absolute_error(y_train, y_pred_train_stacking):.4f}\")\n",
    "print(f\"MAE test   : {mean_absolute_error(y_test,  y_pred_test_stacking):.4f}\")\n",
    "\n",
    "# ANALYSE :\n",
    "# Parmi les méthodes d'ensemble, le Bagging se révèle être le\n",
    "# modèle le plus performant.\n",
    "#\n",
    "# - Bagging : C'est le champion de cette comparaison. Il obtient le meilleur\n",
    "#   score en test (RMSE de 0.99), ce qui représente une nette\n",
    "#   amélioration. Il offre le meilleur compromis performance/robustesse.\n",
    "#\n",
    "# - Boosting : Reste un modèle fiable avec le plus faible sur-apprentissage,\n",
    "#   mais ses performances en test sont inférieures à celles du Bagging.\n",
    "#\n",
    "# - Stacking : Est le moins performant dans cette configuration.\n",
    "#   Il souffre d'un sur-apprentissage élevé et ne parvient pas à\n",
    "#   combiner efficacement les modèles de base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. COMPARAISON DES MODÈLES (Validation Croisée)\n",
      "----------------------------------------------------------------------\n",
      "Modèle               R^2_CV   RMSE_CV  MAE_CV  \n",
      "--------------------------------------------------\n",
      "Baseline (Dummy)     -0.0362  1.4525   1.1336  \n",
      "Régression Linéaire  0.4518   1.0567   0.8321  \n",
      "Meilleur Régularisé  0.4519   1.0566   0.8319  \n",
      "Bagging              0.4252   1.0821   0.8660  \n",
      "Boosting             0.4010   1.1046   0.8772  \n",
      "Stacking             0.5000   1.0089   0.7986  \n",
      "\n",
      "Meilleur modèle (RMSE le plus faible) : Stacking\n",
      "\n",
      "6b. ÉVALUATION FINALE TRAIN / TEST\n",
      "----------------------------------------------------------------------\n",
      "Modèle               R^2 tr/te       RMSE tr/te      MAE tr/te      \n",
      "----------------------------------------------------------------------\n",
      "Baseline (Dummy)     0.000/-0.021   1.444/1.387      1.124/1.129      +0.0%\n",
      "Régression Linéaire  0.524/0.007   0.996/1.368      0.791/0.920      +1.4%\n",
      "Meilleur Régularisé  0.524/0.009   0.996/1.367      0.791/0.920      +1.4%\n",
      "Bagging              0.926/0.327   0.392/1.126      0.308/0.890      +18.8%\n",
      "Boosting             0.579/0.405   0.936/1.059      0.743/0.835      +23.7%\n",
      "Stacking             0.738/0.300   0.739/1.149      0.584/0.863      +17.2%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n6. COMPARAISON DES MODÈLES (Validation Croisée)\")\n",
    "print(\"-\" * 70)\n",
    "# evaluer la meilleure performance de modèles\n",
    "# 1) On rassemble les scores R2, RMSE, MAE calculés en cross-validation pour chaque modèle testé\n",
    "results_cv = {\n",
    "    'Baseline (Dummy)': (\n",
    "        baseline_r2,\n",
    "        baseline_rmse,\n",
    "        baseline_mae\n",
    "    ),\n",
    "    'Régression Linéaire': (\n",
    "        cv_linear ['test_R2'].mean(),\n",
    "        -cv_linear ['test_RMSE'].mean(),\n",
    "        -cv_linear ['test_MAE'].mean()\n",
    "    ),\n",
    "    \n",
    "    'Meilleur Régularisé': (\n",
    "        best_reg_r2,      \n",
    "        best_reg_rmse,\n",
    "        best_reg_mae\n",
    "    ),\n",
    "    'Bagging': (\n",
    "        cv_bagging['test_R2'].mean(),\n",
    "        -cv_bagging['test_RMSE'].mean(),\n",
    "        -cv_bagging['test_MAE'].mean()\n",
    "    ),\n",
    "    'Boosting': (\n",
    "        cv_boost_results['test_R2'].mean(),\n",
    "        -cv_boost_results['test_RMSE'].mean(),\n",
    "        -cv_boost_results['test_MAE'].mean()\n",
    "    ),\n",
    "    'Stacking': (\n",
    "        cv_stacking['test_R2'].mean(),\n",
    "        -cv_stacking['test_RMSE'].mean(),\n",
    "        -cv_stacking['test_MAE'].mean()\n",
    "    )\n",
    "}\n",
    "# Affichage des résultats CV\n",
    "print(f\"{'Modèle':<20} {'R^2_CV':<8} {'RMSE_CV':<8} {'MAE_CV':<8}\")\n",
    "print(\"-\" * 50)\n",
    "for name, (r2, rmse, mae) in results_cv.items():\n",
    "    print(f\"{name:<20} {r2:<8.4f} {rmse:<8.4f} {mae:<8.4f}\")\n",
    "# Sélection du meilleur modèle en fonction du plus faible RMSE\n",
    "best_model_name = min(results_cv.keys(), key=lambda x: results_cv[x][1])\n",
    "print(f\"\\nMeilleur modèle (RMSE le plus faible) : {best_model_name}\")\n",
    "\n",
    "# 2) Évaluation finale (train vs test)\n",
    "print(\"\\n6b. ÉVALUATION FINALE TRAIN / TEST\")\n",
    "print(\"-\" * 70)\n",
    "# Ici on refait une évaluation sur train / test pour comparer : R2, RMSE et MAE sur train et test\n",
    "# On calcule aussi l'amélioration en RMSE par rapport au Dummy sur le test\n",
    "# et La cohérence entre RMSE CV et RMSE test\n",
    "print(f\"{'Modèle':<20} {'R^2 tr/te':<15} {'RMSE tr/te':<15} {'MAE tr/te':<15}\")\n",
    "print(\"-\" * 70)\n",
    "# Map des modèles entraînés avec les meilleurs hyperparamètres\n",
    "models_map = {\n",
    "    'Baseline (Dummy)': dummy_pipe,\n",
    "    'Régression Linéaire': linear_pipe,\n",
    "    'Meilleur Régularisé': gs_reg.best_estimator_,\n",
    "    'Bagging': bagging_pipe,\n",
    "    'Boosting': gs_boost.best_estimator_,\n",
    "    'Stacking': stacking_pipe\n",
    "}\n",
    "\n",
    "for name, mdl in models_map.items():\n",
    "    # Réentraîner sur train complet\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_tr = mdl.predict(X_train)\n",
    "    y_te = mdl.predict(X_test)\n",
    "     # Scores train/test\n",
    "    r2_tr = r2_score(y_train, y_tr)\n",
    "    r2_te = r2_score(y_test,  y_te)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(y_train, y_tr))\n",
    "    rmse_te = np.sqrt(mean_squared_error(y_test,  y_te))\n",
    "    mae_tr  = mean_absolute_error(y_train, y_tr)\n",
    "    mae_te  = mean_absolute_error(y_test,  y_te)\n",
    "    # amélioration vs baseline (Dummy)\n",
    "    dummy_rmse = np.sqrt(mean_squared_error(y_test, dummy_pipe.predict(X_test)))\n",
    "    improvement = (dummy_rmse - rmse_te) / dummy_rmse * 100\n",
    "    # cohérence CV/Test RMSE\n",
    "    cv_rmse = results_cv[name][1]\n",
    "    \n",
    "    #affichage\n",
    "    print(f\"{name:<20} {r2_tr:.3f}/{r2_te:.3f}   \"\n",
    "      f\"{rmse_tr:.3f}/{rmse_te:.3f}      \"\n",
    "      f\"{mae_tr:.3f}/{mae_te:.3f}      \"\n",
    "      f\"{improvement:+.1f}%\")\n",
    "          \n",
    "    #Gain net par rapport au Dummy valide l'intérêt du modèle, mais CV vs test assez inégal (16 %), \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 7. CONCLUSION ET JUSTIFICATIONS TECHNIQUES\n",
    " \n",
    "\n",
    "**Métrique choisie : RMSE**  \n",
    "Pénalise fortement les grosses erreurs, critique pour la prédiction d’émissions de carbone où les écarts importants sont coûteux.\n",
    "Je choisis ici de prendre la métrique RMSE car elle pénalise fortement les sous ou sur-estimations ce qui est crucial dans les données de type émission de carbone, elle est exprimée dans la même unité que la cible et enfin elle complète la mesure du R^2 en donnant une mesure concrète de l erreur moyenne attendue \n",
    "\n",
    "\n",
    "Les modèles Régression Linéaire et Meilleur Régularisé ont montré leurs limites sur ce problème. Avec des scores R² de test proches de zéro, ils ne parviennent pas à capturer la complexité des données. Cela confirme que le problème est non-linéaire et que les modèles d'ensemble sont une direction beaucoup plus prometteuse.\n",
    "\n",
    "Modèle final sélectionné : Gradient Boosting\n",
    "Après une comparaison rigoureuse, le modèle Gradient Boosting est sélectionné comme étant le plus performant et le plus fiable pour cette tâche de prédiction.\n",
    "\n",
    "RMSE Test : 1.059 (le plus faible de tous les modèles en conditions réelles)\n",
    "\n",
    "R² Test : 0.405 (le score le plus élevé, expliquant le plus de variance)\n",
    "\n",
    "Amélioration vs baseline : +23.7 % (l'amélioration la plus significative)\n",
    "\n",
    "Le Gradient Boosting offre donc le meilleur compromis performance/fiabilité :\n",
    "\n",
    "Sa performance supérieure sur les données de test.\n",
    "\n",
    "Sa stabilité et sa capacité à généraliser (faible écart CV/Test).\n",
    "\n",
    "Sa robustesse face au bruit, en corrigeant séquentiellement ses erreurs.\n",
    "\n",
    "La meilleure réduction d'erreur par rapport au modèle de base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
