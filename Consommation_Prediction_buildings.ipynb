{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les bibliotheques nécessaires\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689dcef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. CHARGEMENT DES DONNÉES\n",
      "Shape des données : (669, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['PropertyGFATotal', 'PropertyGFABuilding(s)', 'NumberofFloors',\n",
       "       'NumberofBuildings', 'YearBuilt', 'PrimaryPropertyType',\n",
       "       'LargestPropertyUseTypeGFA', 'ZipCode', 'Neighborhood', 'Latitude',\n",
       "       'Longitude', 'ENERGYSTARScore', 'log_TotalGHGEmissions',\n",
       "       'log_SiteEnergyUse_kBtu', 'BuildingAge', 'AvgFloorArea',\n",
       "       'GFATotal_per_Building', 'PrimaryPropertyType_grouped',\n",
       "       'log_PropertyGFATotal', 'log_LargestPropertyUseTypeGFA',\n",
       "       'log_AvgFloorArea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n1. CHARGEMENT DES DONNÉES\")\n",
    "df_engineered = pd.read_csv(\"donnees_ameliorees.csv\")\n",
    "print(f\"Shape des données : {df_engineered.shape}\")\n",
    "df_engineered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6431b489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features et nouvelle cible sélectionnées.\n",
      "\n",
      "✓ Données prêtes pour l'entraînement (avec division stratifiée) :\n",
      "  - Taille de X_train : (535, 9)\n",
      "  - Taille de X_test : (134, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## DÉFINITION DES FEATURES ET DE LA CIBLE\n",
    "# On définit la nouvelle cible\n",
    "target = 'log_SiteEnergyUse_kBtu'\n",
    "\n",
    "# Listes de features \n",
    "numerical_features = [\n",
    "    'log_PropertyGFATotal', 'log_LargestPropertyUseTypeGFA', 'log_AvgFloorArea',\n",
    "    'BuildingAge', 'NumberofFloors', 'NumberofBuildings', 'Latitude', 'Longitude'\n",
    "]\n",
    "categorical_features = ['PrimaryPropertyType_grouped']\n",
    "\n",
    "all_features = numerical_features + categorical_features\n",
    "\n",
    "# On crée X et y\n",
    "X = df_engineered[all_features]\n",
    "y = df_engineered[target]\n",
    "\n",
    "print(\"✓ Features et nouvelle cible sélectionnées.\")\n",
    "\n",
    "# DÉFINITION DU PREPROCESSEUR ET DIVISION STRATIFIÉE DES DONNÉES\n",
    "\n",
    "#préprocesseur\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "#  On crée des catégories (strates) à partir de la cible continue\n",
    "y_strat = pd.qcut(y, q=4, labels=False, duplicates='drop')\n",
    "\n",
    "# On utilise ces strates dans le train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_strat # Ajout de la stratification\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Données prêtes pour l'entraînement (avec division stratifiée) :\")\n",
    "print(f\"  - Taille de X_train : {X_train.shape}\")\n",
    "print(f\"  - Taille de X_test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51f5ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration de la validation croisée \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# 1. Créer les catégories (strates) à partir de la variable cible 'y'\n",
    "#    Cette étape est indispensable pour la stratification en régression.\n",
    "y_strat = pd.qcut(y, q=4, labels=False, duplicates='drop')\n",
    "\n",
    "# 2. Définir l'objet de validation croisée stratifiée à utiliser dans les GridSearchCV\n",
    "\n",
    "cv_strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste des métriques \n",
    "scoring = {\n",
    "    'MAE':  'neg_mean_absolute_error',\n",
    "    'RMSE': 'neg_root_mean_squared_error', \n",
    "    'R2':   'r2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe167925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MODÈLE BASELINE (DummyRegressor)\n",
      "--------------------------------------------------\n",
      "Baseline (DummyRegressor - moyenne) :\n",
      "  R2 CV    : -0.0135 ± 0.0075\n",
      "  RMSE CV  : 1.2054 ± 0.1155\n",
      "  MAE CV   : 0.9522 ± 0.1024\n",
      " on note ici que nos modèles à entrainer doivent avoir des résultats inférieurs au niveau des RMSE et MAE à ces moyennes de base\n",
      " pour le coefficent de détermination (R^2) l'objectif est d'avoir une valeur supérieure à - 0.0135, l'idéal étant un score positif\n"
     ]
    }
   ],
   "source": [
    "# mise en place du modèle de base DummyRegressor - prédit juste la moyenne\n",
    "print(\"1. MODÈLE BASELINE (DummyRegressor)\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "dummy_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', DummyRegressor(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Cross-validation du baseline\n",
    "cv_dummy = cross_validate(dummy_pipe, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "baseline_r2 = cv_dummy['test_R2'].mean()\n",
    "baseline_rmse = -cv_dummy['test_RMSE'].mean()\n",
    "baseline_mae = -cv_dummy['test_MAE'].mean()\n",
    "\n",
    "print(f\"Baseline (DummyRegressor - moyenne) :\")\n",
    "print(f\"  R2 CV    : {baseline_r2:.4f} ± {cv_dummy['test_R2'].std():.4f}\")\n",
    "print(f\"  RMSE CV  : {baseline_rmse:.4f} ± {cv_dummy['test_RMSE'].std():.4f}\")\n",
    "print(f\"  MAE CV   : {baseline_mae:.4f} ± {cv_dummy['test_MAE'].std():.4f}\")\n",
    "print(f\" on note ici que nos modèles à entrainer doivent avoir des résultats inférieurs au niveau des RMSE et MAE à ces moyennes de base\") \n",
    "print(f\" pour le coefficent de détermination (R^2) l'objectif est d'avoir une valeur supérieure à - 0.0135, l'idéal étant un score positif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eba2673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. RÉGRESSION LINÉAIRE SIMPLE\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R^2 train CV : 0.7072 ± 0.0122\n",
      "  R^2  test  CV : 0.6603 ± 0.0330\n",
      "  RMSE train CV : 0.6529 ± 0.0161\n",
      "  RMSE test  CV : 0.6955 ± 0.0606\n",
      "  MAE train CV  : 0.4923 ± 0.0117\n",
      "  MAE test  CV  : 0.5292 ± 0.0447\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. RÉGRESSION LINÉAIRE SIMPLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# La régression linéaire sert de baseline pour comprendre\n",
    "# les relations linéaires dans nos données avant d'ajouter de la régularisation\n",
    "linear_pipe = Pipeline([('prep', preproc), ('model', LinearRegression())])\n",
    "cv_linear  = cross_validate(\n",
    "    linear_pipe,\n",
    "    X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True   # ← on récupère train_X et test_X\n",
    ")\n",
    "# très bon résultat et  point de départ, il explique 66 % de la variance, écart train/test limité (~0.04).\n",
    "print(f\"  R^2 train CV : {cv_linear ['train_R2'].mean():.4f} ± {cv_linear ['train_R2'].std():.4f}\")\n",
    "print(f\"  R^2  test  CV : {cv_linear ['test_R2'].mean():.4f} ± {cv_linear ['test_R2'].std():.4f}\")\n",
    "print(f\"  RMSE train CV : {-cv_linear ['train_RMSE'].mean():.4f} ± {cv_linear ['train_RMSE'].std():.4f}\")\n",
    "print(f\"  RMSE test  CV : {-cv_linear ['test_RMSE'].mean():.4f} ± {cv_linear ['test_RMSE'].std():.4f}\")\n",
    "print(f\"  MAE train CV  : {-cv_linear ['train_MAE'].mean():.4f} ± {cv_linear ['train_MAE'].std():.4f}\")\n",
    "print(f\"  MAE test  CV  : {-cv_linear ['test_MAE'].mean():.4f} ± {cv_linear ['test_MAE'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8246c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. MODÈLES RÉGULARISÉS (Ridge, Lasso, ElasticNet)\n",
      "--------------------------------------------------\n",
      "Optimisation des hyperparamètres par GridSearchCV...\n",
      "\n",
      "=== Résultats Régularisation ===\n",
      "\n",
      "Ridge :\n",
      "  Meilleurs paramètres : {'model': Ridge(), 'model__alpha': 0.1}\n",
      "  R^2 train CV : 0.7072\n",
      "  R^2 test  CV : 0.6603\n",
      "  RMSE train CV : 0.6530\n",
      "  RMSE test  CV : 0.6955\n",
      "  MAE train CV  : 0.4923\n",
      "  MAE test  CV  : 0.5293\n",
      "\n",
      "Lasso :\n",
      "  Meilleurs paramètres : {'model': Lasso(), 'model__alpha': 0.01}\n",
      "  R^2 train CV : 0.6926\n",
      "  R^2 test  CV : 0.6483\n",
      "  RMSE train CV : 0.6690\n",
      "  RMSE test  CV : 0.7095\n",
      "  MAE train CV  : 0.5110\n",
      "  MAE test  CV  : 0.5409\n",
      "\n",
      "ElasticNet :\n",
      "  Meilleurs paramètres : {'model': ElasticNet(), 'model__alpha': 0.01, 'model__l1_ratio': 0.1}\n",
      "  R^2 train CV : 0.7005\n",
      "  R^2 test  CV : 0.6557\n",
      "  RMSE train CV : 0.6604\n",
      "  RMSE test  CV : 0.7011\n",
      "  MAE train CV  : 0.4999\n",
      "  MAE test  CV  : 0.5349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"3. MODÈLES RÉGULARISÉS (Ridge, Lasso, ElasticNet)\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "#  La régularisation aide à :\n",
    "# - Ridge : réduire l'overfitting en pénalisant les coefficients élevés\n",
    "# - Lasso : sélection de variables en annulant certains coefficients\n",
    "# - ElasticNet : combinaison des avantages de Ridge et Lasso\n",
    "# modèles linéaires\n",
    "\n",
    "# Pipeline de base\n",
    "reg_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', Ridge())  # Placeholder qui sera remplacé par GridSearchCV\n",
    "])\n",
    "\n",
    "# Grille de paramètres - pour tester plusieurs combinaisons d'hyperparamètres pour donner le meilleur compromis biais/variance \n",
    "#alpha = force de pénalité pour essayer de réduire la variance (moins de sur-entrainement), stabiliser les poids de chaque feature, et sélectionner des variables via Lasso si nécessaire\n",
    "#Rideg pénalise la somme dess poids au carré, plus Alpha est grand plus les coeff sont retrécies vers 0, Lasso pénalise la somme des valeurs absolues et Elastic net combien les 2 (sélection et stabilisation)\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [Ridge()],\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0] # échelle logarithmique pour balayer plusieurs ordres de grandeur \n",
    "        #et voir si le modèle préfère une pénalité nulle, modérée ou forte\n",
    "    },\n",
    "    {\n",
    "        'model': [Lasso()],\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]  #idem\n",
    "    },\n",
    "    {\n",
    "        'model': [ElasticNet()],\n",
    "        'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'model__l1_ratio': [0.1, 0.5, 0.7, 0.9] # curseur de mélange pour \"doser\" Lasso et Ridge - exemple 0.5 c'est 50% de Lasso et 50% de Ridge , 0.9 surtout Lasso et peu de Ridge\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Optimisation des hyperparamètres par GridSearchCV...\")\n",
    "gs_reg = GridSearchCV(\n",
    "    reg_pipe,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='RMSE', #moins standart que R^2 mais logique dans ma démarche\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # important pour avoir mean_train_...\n",
    ")\n",
    "gs_reg.fit(X_train, y_train) #on fit le jeu de données\n",
    "\n",
    "cv_res = gs_reg.cv_results_\n",
    "best_idx = gs_reg.best_index_   # l’indice de la meilleure config trouvée\n",
    "\n",
    "best_reg_r2   = cv_res['mean_test_R2'][best_idx]\n",
    "best_reg_rmse = -cv_res['mean_test_RMSE'][best_idx]\n",
    "best_reg_mae  = -cv_res['mean_test_MAE'][best_idx]\n",
    "\n",
    "# On récupère les meilleurs index par type\n",
    "best_ridge_idx = None\n",
    "best_lasso_idx = None\n",
    "best_enet_idx = None\n",
    "\n",
    "for i, p in enumerate(cv_res['params']):\n",
    "    if isinstance(p['model'], Ridge):\n",
    "        if best_ridge_idx is None or cv_res['mean_test_R2'][i] > cv_res['mean_test_R2'][best_ridge_idx]:\n",
    "            best_ridge_idx = i\n",
    "    elif isinstance(p['model'], Lasso):\n",
    "        if best_lasso_idx is None or cv_res['mean_test_R2'][i] > cv_res['mean_test_R2'][best_lasso_idx]:\n",
    "            best_lasso_idx = i\n",
    "    elif p['model'].__class__.__name__ == 'ElasticNet':\n",
    "        if best_enet_idx is None or cv_res['mean_test_R2'][i] > cv_res['mean_test_R2'][best_enet_idx]:\n",
    "            best_enet_idx = i\n",
    "\n",
    "print(\"\\n=== Résultats Régularisation ===\")\n",
    "\n",
    "for name, idx in [('Ridge', best_ridge_idx), ('Lasso', best_lasso_idx), ('ElasticNet', best_enet_idx)]:\n",
    "    if idx is None:\n",
    "        print(f\"{name} : Non testé\")\n",
    "        continue\n",
    "   \n",
    "    print(f\"\\n{name} :\")\n",
    "    print(f\"  Meilleurs paramètres : {cv_res['params'][idx]}\")\n",
    "    print(f\"  R^2 train CV : {cv_res['mean_train_R2'][idx]:.4f}\")\n",
    "    print(f\"  R^2 test  CV : {cv_res['mean_test_R2'][idx]:.4f}\")\n",
    "    print(f\"  RMSE train CV : {-cv_res['mean_train_RMSE'][idx]:.4f}\")\n",
    "    print(f\"  RMSE test  CV : {-cv_res['mean_test_RMSE'][idx]:.4f}\")\n",
    "    print(f\"  MAE train CV  : {-cv_res['mean_train_MAE'][idx]:.4f}\")\n",
    "    print(f\"  MAE test  CV  : {-cv_res['mean_test_MAE'][idx]:.4f}\")\n",
    "# ANALYSE :\n",
    "#les 3 modèles sont très bien régularisés, les variances sont faibles\n",
    "# Le modèle Ridge se distingue comme le plus performant. Il obtient le meilleur score R² en validation croisée (0.6603) et \n",
    "# l'erreur RMSE la plus faible (0.6955).\n",
    "#  Cela signifie qu'il est le plus précis des trois pour prédire notre cible.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b31dea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Première exploration des modèles non-linéaires (GradientBoosting et Random Forest)\n",
      "--------------------------------------------------\n",
      "→ Meilleurs params GradientBoost : {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "→ Meilleurs params RF : {'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "\n",
      "=== Résultats Gradient Boosting ===\n",
      "R^2 train CV : 0.8765\n",
      "R^2 test  CV : 0.6361\n",
      "RMSE train CV : 0.4242\n",
      "RMSE test  CV : 0.7223\n",
      "MAE train CV : 0.3241\n",
      "MAE test  CV : 0.5492\n",
      "\n",
      "=== Résultats Random Forest ===\n",
      "R^2 train CV : 0.9223\n",
      "R^2 test  CV : 0.6229\n",
      "RMSE train CV : 0.3366\n",
      "RMSE test  CV : 0.7355\n",
      "MAE train CV : 0.2664\n",
      "MAE test  CV : 0.5596\n"
     ]
    }
   ],
   "source": [
    "print(\"4. Première exploration des modèles non-linéaires (GradientBoosting et Random Forest)\")\n",
    "print(\"-\"*50)\n",
    "# modèles d'arbres décisionnels - non linéaires - POUR VOIR SI ILS SURPASSENT LES MODELES LINEAIRES\n",
    "# --- Pipeline pour le Gradient Boosting ---\n",
    "boost_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# --- Grille d’hyper-paramètres (préfixe 'model__') ---\n",
    "param_grid_boost = {\n",
    "    'model__n_estimators':  [100, 200, 300], # nombre d'arbres déterminés, plus il y a d'arbres plus le modèle est capable de corriger les erreurs résiduelles mais plus long à entraîner\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2], # taux apprentissage - plus il est grand plus le modèle apprend vite mais risque de sur-apprentissage - 0.1 valeur par défaut - 0.01 plus lent mais plus stable et 0.2 plus rapide\n",
    "    'model__max_depth':     [3, 5, 7] # profondeur des arbres - 3 classique, 5 à 7 plus de flexibilité mais plus risqué\n",
    "}\n",
    "\n",
    "# --- Lancement de la GridSearch ---\n",
    "gs_boost = GridSearchCV(\n",
    "    boost_pipe,\n",
    "    param_grid_boost,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    refit='RMSE'\n",
    ")\n",
    "gs_boost.fit(X_train, y_train)\n",
    "print(\"→ Meilleurs params GradientBoost :\", gs_boost.best_params_)\n",
    "\n",
    "# Pipeline pour Random Forest\n",
    "rf_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Grille de recherche (attention au préfixe model__)\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth':    [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Lancement de la GridSearch\n",
    "gs_rf = GridSearchCV(\n",
    "    rf_pipe,\n",
    "    param_grid_rf,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    refit='RMSE',\n",
    "    return_train_score=True\n",
    ")\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(\"→ Meilleurs params RF :\", gs_rf.best_params_)\n",
    "\n",
    "# Récupère tous les scores CV pour Gradient Boosting\n",
    "cv_boost = gs_boost.cv_results_\n",
    "best_boost_idx = gs_boost.best_index_\n",
    "\n",
    "print(\"\\n=== Résultats Gradient Boosting ===\")\n",
    "print(f\"R^2 train CV : {cv_boost['mean_train_R2'][best_boost_idx]:.4f}\")\n",
    "print(f\"R^2 test  CV : {cv_boost['mean_test_R2'][best_boost_idx]:.4f}\")\n",
    "print(f\"RMSE train CV : {-cv_boost['mean_train_RMSE'][best_boost_idx]:.4f}\")\n",
    "print(f\"RMSE test  CV : {-cv_boost['mean_test_RMSE'][best_boost_idx]:.4f}\")\n",
    "print(f\"MAE train CV : {-cv_boost['mean_train_MAE'][best_boost_idx]:.4f}\")\n",
    "print(f\"MAE test  CV : {-cv_boost['mean_test_MAE'][best_boost_idx]:.4f}\")\n",
    "\n",
    "# Idem pour Random Forest\n",
    "cv_rf = gs_rf.cv_results_\n",
    "best_rf_idx = gs_rf.best_index_\n",
    "\n",
    "print(\"\\n=== Résultats Random Forest ===\")\n",
    "print(f\"R^2 train CV : {cv_rf['mean_train_R2'][best_rf_idx]:.4f}\")\n",
    "print(f\"R^2 test  CV : {cv_rf['mean_test_R2'][best_rf_idx]:.4f}\")\n",
    "print(f\"RMSE train CV : {-cv_rf['mean_train_RMSE'][best_rf_idx]:.4f}\")\n",
    "print(f\"RMSE test  CV : {-cv_rf['mean_test_RMSE'][best_rf_idx]:.4f}\")\n",
    "print(f\"MAE train CV : {-cv_rf['mean_train_MAE'][best_rf_idx]:.4f}\")\n",
    "print(f\"MAE test  CV : {-cv_rf['mean_test_MAE'][best_rf_idx]:.4f}\")\n",
    "\n",
    "# ANALYSE :\n",
    "#Le modèle Gradient Boosting est le meilleur des deux.\n",
    "\n",
    "#Analyse des résultats\n",
    "\n",
    "#1. Le Gradient Boosting est plus performant\n",
    "# Il obtient de meilleurs scores sur l'ensemble des métriques de test :\n",
    "\n",
    "#R² test CV : 0.6361 (contre 0.6229 pour le Random Forest)\n",
    "\n",
    "#RMSE test CV : 0.7223 (contre 0.7355)\n",
    "\n",
    "#MAE test CV : 0.5492 (contre 0.5596)\n",
    "\n",
    "#Cela signifie qu'il est globalement plus précis et commet des erreurs moins importantes que le Random Forest.\n",
    "\n",
    "#2. Le Gradient Boosting est plus robuste\n",
    "# Les deux modèles font du surapprentissage (overfitting), ce qui est normal pour des modèles à base d'arbres. \n",
    "# Cependant, le Gradient Boosting est mieux maîtrisé :\n",
    "\n",
    "#Écart R^2 (train/test) pour Gradient Boosting : 0.8765 - 0.6361 = 0.24\n",
    "\n",
    "#Écart R^2 (train/test) pour Random Forest : 0.9223 - 0.6229 = 0.30\n",
    "\n",
    "#L'écart plus faible du Gradient Boosting indique qu'il généralise mieux et est plus fiable sur de nouvelles données.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29fca217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. MÉTHODES D'ENSEMBLE\n",
      "--------------------------------------------------\n",
      "A) BAGGING (Bootstrap Aggregating)\n",
      "R^2 train : 0.9465\n",
      "R^2 test  : 0.6765\n",
      "RMSE train : 0.2795\n",
      "RMSE test  : 0.7343\n",
      "MAE train  : 0.2087\n",
      "MAE test   : 0.5734\n",
      "\n",
      "B) BOOSTING (Gradient Boosting)\n",
      "R^2 train : 0.6812\n",
      "R^2 test  : 0.6172\n",
      "RMSE train : 0.6819\n",
      "RMSE test  : 0.7988\n",
      "MAE train  : 0.5054\n",
      "MAE test   : 0.6100\n",
      "\n",
      "C) STACKING\n",
      "R^2 train : 0.7184\n",
      "R^2 test  : 0.6706\n",
      "RMSE train : 0.6409\n",
      "RMSE test  : 0.7410\n",
      "MAE train  : 0.4840\n",
      "MAE test   : 0.5762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n5. MÉTHODES D'ENSEMBLE\")\n",
    "print(\"-\" * 50)\n",
    "# Techniques pour combiner plusieurs modèles\n",
    "# A) BAGGING - Réduit la variance en combinant plusieurs modèles entraînés sur\n",
    "# différents échantillons des données d'entraînement\n",
    "print(\"A) BAGGING (Bootstrap Aggregating)\")\n",
    "bagging_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', BaggingRegressor(\n",
    "        n_estimators=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "cv_bagging = cross_validate(bagging_pipe, X_train, y_train,cv=cv, scoring=scoring)\n",
    "\n",
    "\n",
    "bagging_pipe.fit(X_train, y_train)\n",
    "y_pred_train_bagging = bagging_pipe.predict(X_train)\n",
    "y_pred_test_bagging  = bagging_pipe.predict(X_test)\n",
    "\n",
    "print(f\"R^2 train : {r2_score(y_train, y_pred_train_bagging):.4f}\") # gain modeste par rapport aux linéaires (≃0.25), mais écart train/test ≃0.26  \n",
    "print(f\"R^2 test  : {r2_score(y_test,  y_pred_test_bagging):.4f}\") # montre un sur‐apprentissage toujours présent.  \n",
    "print(f\"RMSE train : {np.sqrt(mean_squared_error(y_train, y_pred_train_bagging)):.4f}\")\n",
    "print(f\"RMSE test  : {np.sqrt(mean_squared_error(y_test,  y_pred_test_bagging)):.4f}\")\n",
    "print(f\"MAE train  : {mean_absolute_error(y_train, y_pred_train_bagging):.4f}\")\n",
    "print(f\"MAE test   : {mean_absolute_error(y_test,  y_pred_test_bagging):.4f}\")\n",
    "\n",
    "# B) BOOSTING\n",
    "print(\"\\nB) BOOSTING (Gradient Boosting)\")\n",
    "# Justification : Réduit le biais en combinant séquentiellement des modèles faibles,\n",
    "# chaque nouveau modèle corrigeant les erreurs du précédent\n",
    "\n",
    "boosting_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', HistGradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Optimisation des hyperparamètres pour le boosting\n",
    "param_grid_boost = {\n",
    "    'model__max_iter': [100, 200],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__max_leaf_nodes': [3, 5]\n",
    "}\n",
    "\n",
    "gs_boost = GridSearchCV(boosting_pipe, param_grid_boost, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_boost.fit(X_train, y_train)\n",
    "\n",
    "cv_boost_results = cross_validate(gs_boost.best_estimator_, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "best_boost = gs_boost.best_estimator_\n",
    "best_boost.fit(X_train, y_train)\n",
    "y_pred_train_boost = best_boost.predict(X_train)\n",
    "y_pred_test_boost  = best_boost.predict(X_test)\n",
    "print(f\"R^2 train : {r2_score(y_train, y_pred_train_boost):.4f}\") #étonnant - même résultat que bagging \n",
    "print(f\"R^2 test  : {r2_score(y_test,  y_pred_test_boost):.4f}\")\n",
    "print(f\"RMSE train : {np.sqrt(mean_squared_error(y_train, y_pred_train_boost)):.4f}\")\n",
    "print(f\"RMSE test  : {np.sqrt(mean_squared_error(y_test,  y_pred_test_boost)):.4f}\")\n",
    "print(f\"MAE train  : {mean_absolute_error(y_train, y_pred_train_boost):.4f}\")\n",
    "print(f\"MAE test   : {mean_absolute_error(y_test,  y_pred_test_boost):.4f}\")\n",
    "\n",
    "# C) STACKING\n",
    "print(\"\\nC) STACKING\")\n",
    "# Justification : Combine les prédictions de plusieurs modèles via un meta-learner\n",
    "# qui apprend comment optimiser la combinaison\n",
    "\n",
    "# Modèles de base pour le stacking\n",
    "base_models = [\n",
    "    ('ridge', gs_reg.best_estimator_['model']),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    ('gb', gs_boost.best_estimator_['model'])\n",
    "]\n",
    "\n",
    "stacking_pipe = Pipeline([\n",
    "    ('prep', preproc),\n",
    "    ('model', StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LinearRegression(),\n",
    "        cv=3,  # CV interne pour éviter l'overfitting\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv_stacking = cross_validate(stacking_pipe, X_train, y_train, cv=cv, scoring=scoring)\n",
    "stacking_pipe.fit(X_train, y_train)\n",
    "y_pred_train_stacking = stacking_pipe.predict(X_train)\n",
    "y_pred_test_stacking  = stacking_pipe.predict(X_test)\n",
    "print(f\"R^2 train : {r2_score(y_train, y_pred_train_stacking):.4f}\") \n",
    "print(f\"R^2 test  : {r2_score(y_test,  y_pred_test_stacking):.4f}\")     \n",
    "print(f\"RMSE train : {np.sqrt(mean_squared_error(y_train, y_pred_train_stacking)):.4f}\")\n",
    "print(f\"RMSE test  : {np.sqrt(mean_squared_error(y_test,  y_pred_test_stacking)):.4f}\")\n",
    "print(f\"MAE train  : {mean_absolute_error(y_train, y_pred_train_stacking):.4f}\")\n",
    "print(f\"MAE test   : {mean_absolute_error(y_test,  y_pred_test_stacking):.4f}\")\n",
    "\n",
    "# ANALYSE :\n",
    "# Parmi les méthodes d'ensemble, le stacking se révèle être le\n",
    "# modèle le plus performant et robuste:\n",
    "\n",
    "#R² test : 0.6765 (le plus élevé)\n",
    "#RMSE test : 0.7343 (le plus bas, à égalité avec le Bagging)\n",
    "# MAE test : 0.5734 (le plus bas, à égalité avec le Bagging)\n",
    "\n",
    "#Écart R² (train/test) pour Stacking : 0.7184 - 0.6706 = 0.0478\n",
    "#Écart R² (train/test) pour Boosting : 0.6812 - 0.6172 = 0.0640\n",
    "#Écart R² (train/test) pour Bagging : 0.9465 - 0.6765 = 0.2700\n",
    "\n",
    "#Le modèle de Bagging, malgré de bons scores en test, souffre d'un surapprentissage très important et est donc moins fiable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "066d8788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. COMPARAISON DES MODÈLES (Validation Croisée)\n",
      "----------------------------------------------------------------------\n",
      "Modèle               R^2_CV   RMSE_CV  MAE_CV  \n",
      "--------------------------------------------------\n",
      "Baseline (Dummy)     -0.0135  1.2054   0.9522  \n",
      "Régression Linéaire  0.6603   0.6955   0.5292  \n",
      "Meilleur Régularisé  0.6603   0.6955   0.5293  \n",
      "Bagging              0.6143   0.7439   0.5669  \n",
      "Boosting             0.5773   0.7787   0.5826  \n",
      "Stacking             0.6624   0.6939   0.5303  \n",
      "\n",
      "Meilleur modèle (RMSE le plus faible) : Stacking\n",
      "Meilleur modèle de l'entrainement\n",
      "\n",
      "6b. ÉVALUATION FINALE TRAIN / TEST\n",
      "----------------------------------------------------------------------\n",
      "Modèle               R^2 tr/te       RMSE tr/te      MAE tr/te      \n",
      "----------------------------------------------------------------------\n",
      "Baseline (Dummy)     0.000/-0.000   1.208/1.291      0.950/0.987      +0.0%\n",
      "Régression Linéaire  0.704/0.659   0.657/0.754      0.496/0.592      +41.6%\n",
      "Meilleur Régularisé  0.704/0.659   0.657/0.754      0.496/0.591      +41.6%\n",
      "Bagging              0.946/0.677   0.279/0.734      0.209/0.573      +43.1%\n",
      "Boosting             0.681/0.617   0.682/0.799      0.505/0.610      +38.1%\n",
      "Stacking             0.718/0.671   0.641/0.741      0.484/0.576      +42.6%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n6. COMPARAISON DES MODÈLES (Validation Croisée)\")\n",
    "print(\"-\" * 70)\n",
    "# evaluer la meilleure performance de modèles\n",
    "# 1) On rassemble les scores R2, RMSE, MAE calculés en cross-validation pour chaque modèle testé\n",
    "results_cv = {\n",
    "    'Baseline (Dummy)': (\n",
    "        baseline_r2,\n",
    "        baseline_rmse,\n",
    "        baseline_mae\n",
    "    ),\n",
    "    'Régression Linéaire': (\n",
    "        cv_linear ['test_R2'].mean(),\n",
    "        -cv_linear ['test_RMSE'].mean(),\n",
    "        -cv_linear ['test_MAE'].mean()\n",
    "    ),\n",
    "    \n",
    "    'Meilleur Régularisé': (\n",
    "        best_reg_r2,      \n",
    "        best_reg_rmse,\n",
    "        best_reg_mae\n",
    "    ),\n",
    "    'Bagging': (\n",
    "        cv_bagging['test_R2'].mean(),\n",
    "        -cv_bagging['test_RMSE'].mean(),\n",
    "        -cv_bagging['test_MAE'].mean()\n",
    "    ),\n",
    "    'Boosting': (\n",
    "        cv_boost_results['test_R2'].mean(),\n",
    "        -cv_boost_results['test_RMSE'].mean(),\n",
    "        -cv_boost_results['test_MAE'].mean()\n",
    "    ),\n",
    "    'Stacking': (\n",
    "        cv_stacking['test_R2'].mean(),\n",
    "        -cv_stacking['test_RMSE'].mean(),\n",
    "        -cv_stacking['test_MAE'].mean()\n",
    "    )\n",
    "}\n",
    "# Affichage des résultats CV\n",
    "print(f\"{'Modèle':<20} {'R^2_CV':<8} {'RMSE_CV':<8} {'MAE_CV':<8}\")\n",
    "print(\"-\" * 50)\n",
    "for name, (r2, rmse, mae) in results_cv.items():\n",
    "    print(f\"{name:<20} {r2:<8.4f} {rmse:<8.4f} {mae:<8.4f}\")\n",
    "# Sélection du meilleur modèle en fonction du plus faible RMSE\n",
    "best_model_name = min(results_cv.keys(), key=lambda x: results_cv[x][1])\n",
    "print(f\"\\nMeilleur modèle (RMSE le plus faible) : {best_model_name}\")\n",
    "print (f'Meilleur modèle de l\\'entrainement')\n",
    "\n",
    "# 2) Évaluation finale (train vs test)\n",
    "print(\"\\n6b. ÉVALUATION FINALE TRAIN / TEST\")\n",
    "print(\"-\" * 70)\n",
    "# Ici on refait une évaluation sur train / test pour comparer : R2, RMSE et MAE sur train et test\n",
    "# On calcule aussi l'amélioration en RMSE par rapport au Dummy sur le test\n",
    "# et La cohérence entre RMSE CV et RMSE test\n",
    "print(f\"{'Modèle':<20} {'R^2 tr/te':<15} {'RMSE tr/te':<15} {'MAE tr/te':<15}\")\n",
    "print(\"-\" * 70)\n",
    "# Map des modèles entraînés avec les meilleurs hyperparamètres\n",
    "models_map = {\n",
    "    'Baseline (Dummy)': dummy_pipe,\n",
    "    'Régression Linéaire': linear_pipe,\n",
    "    'Meilleur Régularisé': gs_reg.best_estimator_,\n",
    "    'Bagging': bagging_pipe,\n",
    "    'Boosting': gs_boost.best_estimator_,\n",
    "    'Stacking': stacking_pipe\n",
    "}\n",
    "\n",
    "for name, mdl in models_map.items():\n",
    "    # Réentraîner sur train complet\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_tr = mdl.predict(X_train)\n",
    "    y_te = mdl.predict(X_test)\n",
    "     # Scores train/test\n",
    "    r2_tr = r2_score(y_train, y_tr)\n",
    "    r2_te = r2_score(y_test,  y_te)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(y_train, y_tr))\n",
    "    rmse_te = np.sqrt(mean_squared_error(y_test,  y_te))\n",
    "    mae_tr  = mean_absolute_error(y_train, y_tr)\n",
    "    mae_te  = mean_absolute_error(y_test,  y_te)\n",
    "    # amélioration vs baseline (Dummy)\n",
    "    dummy_rmse = np.sqrt(mean_squared_error(y_test, dummy_pipe.predict(X_test)))\n",
    "    improvement = (dummy_rmse - rmse_te) / dummy_rmse * 100\n",
    "    # cohérence CV/Test RMSE\n",
    "    cv_rmse = results_cv[name][1]\n",
    "    \n",
    "    #affichage\n",
    "    print(f\"{name:<20} {r2_tr:.3f}/{r2_te:.3f}   \"\n",
    "      f\"{rmse_tr:.3f}/{rmse_te:.3f}      \"\n",
    "      f\"{mae_tr:.3f}/{mae_te:.3f}      \"\n",
    "      f\"{improvement:+.1f}%\")\n",
    "          \n",
    "    #Gain net par rapport au Dummy valide l'intérêt du modèle, mais CV vs test assez inégal (16 %), \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous choisissons pour notre cible de consommation d'énergies le modèle stacking pour plusieurs raisons\n",
    "#Meilleure Performance : Il obtient le meilleur score R² (0.671) et l'erreur RMSE la plus faible (0.741) \n",
    "#    sur le jeu de test, le rendant le plus précis.\n",
    "# 2. Excellente Généralisation : Il affiche un très faible écart entre les scores d'entraînement (0.718) \n",
    "#    et de test (0.671), ce qui prouve qu'il n'y a pas de surapprentissage. C'est un modèle robuste.\n",
    "# 3. Supériorité sur les modèles simples : Il surpasse nettement les modèles linéaires, \n",
    "#    ce qui justifie l'utilisation d'une approche plus complexe pour ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a4fb5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de l'optimisation des hyperparamètres du Stacking...\n",
      "Optimisation terminée.\n",
      "Meilleurs hyperparamètres trouvés : {'model__gb__max_depth': 3, 'model__gb__n_estimators': 100, 'model__ridge__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# 1. Définir les modèles de base avec des noms\n",
    "base_models = [\n",
    "    ('ridge', Ridge()),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42))\n",
    "]\n",
    "\n",
    "# 2. Définir le pipeline avec un StackingRegressor complet\n",
    "pipeline_to_improve = Pipeline([\n",
    "    ('prep', preproc), \n",
    "    ('model', StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LinearRegression() # Le méta-modèle\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3. Définir la grille en ciblant les modèles de base\n",
    "# On cible les paramètres du Gradient Boosting ('gb') et du Ridge ('ridge')\n",
    "param_grid = {\n",
    "    'model__gb__n_estimators': [100, 200],\n",
    "    'model__gb__max_depth': [3, 5],\n",
    "    'model__ridge__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# 4. Mettre en place et lancer GridSearchCV (le reste ne change pas)\n",
    "print(\"Lancement de l'optimisation des hyperparamètres du Stacking...\")\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs_final = GridSearchCV(\n",
    "    pipeline_to_improve,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_final.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimisation terminée.\")\n",
    "print(f\"Meilleurs hyperparamètres trouvés : {gs_final.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
